{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9607a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (700000, 26)\n",
      "Test shape: (300000, 25)\n",
      "\n",
      "--- Train Data Head ---\n",
      "   id  age  alcohol_consumption_per_week  physical_activity_minutes_per_week  \\\n",
      "0   0   31                             1                                  45   \n",
      "1   1   50                             2                                  73   \n",
      "2   2   32                             3                                 158   \n",
      "3   3   54                             3                                  77   \n",
      "4   4   54                             1                                  55   \n",
      "\n",
      "   diet_score  sleep_hours_per_day  screen_time_hours_per_day   bmi  \\\n",
      "0         7.7                  6.8                        6.1  33.4   \n",
      "1         5.7                  6.5                        5.8  23.8   \n",
      "2         8.5                  7.4                        9.1  24.1   \n",
      "3         4.6                  7.0                        9.2  26.6   \n",
      "4         5.7                  6.2                        5.1  28.8   \n",
      "\n",
      "   waist_to_hip_ratio  systolic_bp  ...  gender  ethnicity  education_level  \\\n",
      "0                0.93          112  ...  Female   Hispanic       Highschool   \n",
      "1                0.83          120  ...  Female      White       Highschool   \n",
      "2                0.83           95  ...    Male   Hispanic       Highschool   \n",
      "3                0.83          121  ...  Female      White       Highschool   \n",
      "4                0.90          108  ...    Male      White       Highschool   \n",
      "\n",
      "   income_level  smoking_status  employment_status family_history_diabetes  \\\n",
      "0  Lower-Middle         Current           Employed                       0   \n",
      "1  Upper-Middle           Never           Employed                       0   \n",
      "2  Lower-Middle           Never            Retired                       0   \n",
      "3  Lower-Middle         Current           Employed                       0   \n",
      "4  Upper-Middle           Never            Retired                       0   \n",
      "\n",
      "  hypertension_history cardiovascular_history diagnosed_diabetes  \n",
      "0                    0                      0                1.0  \n",
      "1                    0                      0                1.0  \n",
      "2                    0                      0                0.0  \n",
      "3                    1                      0                1.0  \n",
      "4                    1                      0                1.0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "--- Submission Format Example ---\n",
      "       id  diagnosed_diabetes\n",
      "0  700000                   0\n",
      "1  700001                   0\n",
      "2  700002                   0\n",
      "3  700003                   0\n",
      "4  700004                   0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Load the datasets\n",
    "# Assuming the files are in the same directory as your script/notebook\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# 2. Basic sanity check - Print the size of the datasets\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# 3. Look at the first few rows to understand the features\n",
    "print(\"\\n--- Train Data Head ---\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\n--- Submission Format Example ---\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "123bac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Separate Target and ID\n",
    "target = 'diagnosed_diabetes'\n",
    "train_df = train_df.dropna(subset=[target]) \n",
    "\n",
    "y = train_df[target].values # The labels for training\n",
    "train_ids = train_df['id']\n",
    "test_ids = test_df['id']\n",
    "\n",
    "# 2. Drop unnecessary columns\n",
    "train_features = train_df.drop(['id', 'diagnosed_diabetes'], axis=1)\n",
    "test_features = test_df.drop(['id'], axis=1)\n",
    "\n",
    "# 3. Combine temporarily for consistent preprocessing\n",
    "all_features = pd.concat([train_features, test_features], axis=0)\n",
    "\n",
    "# --- START FEATURE ENGINEERING ---\n",
    "\n",
    "# 1. Interaction Features (Continuous)\n",
    "# Multiply features that amplify each other's risk\n",
    "all_features['age_bmi'] = all_features['age'] * all_features['bmi']\n",
    "all_features['age_bp'] = all_features['age'] * all_features['systolic_bp']\n",
    "all_features['bmi_bp'] = all_features['bmi'] * all_features['systolic_bp']\n",
    "\n",
    "# 2. Threshold Features (Binary/Categorical)\n",
    "# Create explicit flags for medical risk groups\n",
    "all_features['is_obese'] = (all_features['bmi'] >= 30).astype(int)\n",
    "all_features['is_overweight'] = ((all_features['bmi'] >= 25) & (all_features['bmi'] < 30)).astype(int)\n",
    "all_features['high_bp'] = (all_features['systolic_bp'] >= 130).astype(int)\n",
    "all_features['is_senior'] = (all_features['age'] >= 65).astype(int)\n",
    "\n",
    "# 3. Lifestyle Risk Score (Ordinal)\n",
    "# Combine negative factors: High BMI + Low Activity + Low Sleep\n",
    "# We cast booleans to int (True=1, False=0) and sum them up\n",
    "all_features['lifestyle_risk'] = (\n",
    "    (all_features['bmi'] > 30).astype(int) + \n",
    "    (all_features['physical_activity_minutes_per_week'] < 60).astype(int) +\n",
    "    (all_features['sleep_hours_per_day'] < 6).astype(int)\n",
    ")\n",
    "\n",
    "# --- END FEATURE ENGINEERING ---\n",
    "\n",
    "# --- IDENTIFY COLUMNS ---\n",
    "\n",
    "# Update Numerical columns to include the NEW continuous interaction features\n",
    "numerical_cols = [\n",
    "    'age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week',\n",
    "    'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day',\n",
    "    'bmi', 'waist_to_hip_ratio', 'systolic_bp',\n",
    "    # NEW FEATURES\n",
    "    'age_bmi', 'age_bp', 'bmi_bp', 'lifestyle_risk'\n",
    "]\n",
    "\n",
    "# Categorical columns (Text/Strings) - Unchanged\n",
    "categorical_cols = [\n",
    "    'gender', 'ethnicity', 'education_level', \n",
    "    'income_level', 'smoking_status', 'employment_status'\n",
    "]\n",
    "\n",
    "# Binary/Already Numeric columns (0/1)\n",
    "# The new binary features (is_obese, etc.) are already 0/1, so we don't scale or encode them.\n",
    "# We just let them pass through.\n",
    "\n",
    "# --- PREPROCESSING ---\n",
    "\n",
    "# A. Handle Categorical Data (One-Hot Encoding)\n",
    "all_features = pd.get_dummies(all_features, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# B. Handle Numerical Data (Scaling)\n",
    "# We now include the new interaction terms in the scaling so they don't dominate gradients\n",
    "scaler = StandardScaler()\n",
    "all_features[numerical_cols] = scaler.fit_transform(all_features[numerical_cols])\n",
    "\n",
    "# C. Handle Missing Values\n",
    "all_features[numerical_cols] = all_features[numerical_cols].fillna(all_features[numerical_cols].mean())\n",
    "all_features = all_features.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e65baa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Input Shape: (560000, 44)\n"
     ]
    }
   ],
   "source": [
    "# --- SPLIT BACK TO TRAIN / TEST ---\n",
    "X = all_features.iloc[:len(train_df)].values\n",
    "X_kaggle_test = all_features.iloc[len(train_df):].values\n",
    "\n",
    "# Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Final Input Shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d4e9820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for non-numeric columns...\n",
      "         0         1         2         3         4         5         6   \\\n",
      "0 -0.373175 -0.073644 -0.106648  0.368804 -1.657032  0.092278  0.635062   \n",
      "1  0.989543   0.87543 -0.379345 -0.380158  1.213476  1.468802  0.844062   \n",
      "2 -1.565553 -0.073644 -0.197547 -1.537644 -0.994607  1.173833  0.112563   \n",
      "3  0.819204 -1.022719 -0.233907  0.232629  0.551051  1.321318 -0.758268   \n",
      "4  0.734034 -0.073644 -0.342985   2.34334 -0.884203  0.928025  0.983395   \n",
      "\n",
      "         7         8   9   ...     34     35     36     37     38     39  \\\n",
      "0  1.865628  0.061517  62  ...  False  False   True  False  False  False   \n",
      "1  1.079128  0.061517  86  ...  False  False  False   True  False   True   \n",
      "2  0.554794  0.693086  64  ...  False  False  False   True  False  False   \n",
      "3 -0.231706 -1.291843  70  ...  False  False  False  False   True  False   \n",
      "4  1.341294  0.422414  69  ...  False  False  False   True  False  False   \n",
      "\n",
      "      40     41     42     43  \n",
      "0  False  False  False  False  \n",
      "1  False  False  False  False  \n",
      "2   True  False  False  False  \n",
      "3   True  False  False  False  \n",
      "4  False  False  False  False  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "SUCCESS: Data converted to float32.\n"
     ]
    }
   ],
   "source": [
    "# 1. Check what columns are causing the issue (Debugging)\n",
    "print(\"Checking for non-numeric columns...\")\n",
    "# Convert back to DataFrame just to see dtypes\n",
    "temp_df = pd.DataFrame(X_train)\n",
    "# Print columns that are of type 'object'\n",
    "print(temp_df.select_dtypes(include=['object']).head())\n",
    "\n",
    "# 2. THE FIX: Force conversion to float32\n",
    "# This will turn Booleans (True/False) into 1.0/0.0\n",
    "# And if there are strings like '1', it converts them. \n",
    "# If there are strings like 'Male', it will crash and tell us exactly which one is wrong.\n",
    "try:\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_val = X_val.astype(np.float32)\n",
    "    y_train = y_train.astype(np.float32)\n",
    "    y_val = y_val.astype(np.float32)\n",
    "    print(\"SUCCESS: Data converted to float32.\")\n",
    "except ValueError as e:\n",
    "    print(\"ERROR: You still have text in your data that cannot be converted!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32106de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting XGBoost Training ---\n",
      "Training Reguralized Model...\n",
      "[0]\tvalidation_0-auc:0.67332\tvalidation_1-auc:0.67452\n",
      "[200]\tvalidation_0-auc:0.69753\tvalidation_1-auc:0.69722\n",
      "[400]\tvalidation_0-auc:0.70513\tvalidation_1-auc:0.70446\n",
      "[600]\tvalidation_0-auc:0.70934\tvalidation_1-auc:0.70814\n",
      "[800]\tvalidation_0-auc:0.71231\tvalidation_1-auc:0.71060\n",
      "[1000]\tvalidation_0-auc:0.71507\tvalidation_1-auc:0.71287\n",
      "[1200]\tvalidation_0-auc:0.71760\tvalidation_1-auc:0.71495\n",
      "[1400]\tvalidation_0-auc:0.71959\tvalidation_1-auc:0.71649\n",
      "[1600]\tvalidation_0-auc:0.72110\tvalidation_1-auc:0.71760\n",
      "[1800]\tvalidation_0-auc:0.72246\tvalidation_1-auc:0.71859\n",
      "[2000]\tvalidation_0-auc:0.72381\tvalidation_1-auc:0.71954\n",
      "[2200]\tvalidation_0-auc:0.72491\tvalidation_1-auc:0.72028\n",
      "[2400]\tvalidation_0-auc:0.72584\tvalidation_1-auc:0.72084\n",
      "[2600]\tvalidation_0-auc:0.72681\tvalidation_1-auc:0.72144\n",
      "[2800]\tvalidation_0-auc:0.72764\tvalidation_1-auc:0.72192\n",
      "[2999]\tvalidation_0-auc:0.72841\tvalidation_1-auc:0.72232\n",
      "\n",
      "Final XGBoost Validation AUC: 0.72232\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"--- Starting XGBoost Training ---\")\n",
    "\n",
    "# 1. Define the Model\n",
    "# We use standard \"starter\" hyperparameters that usually work well\n",
    "xgb_model_v2 = XGBClassifier(\n",
    "    n_estimators=3000,          # Increased, but we rely on early_stopping\n",
    "    learning_rate=0.01,         # Slower learning = better generalization\n",
    "    \n",
    "    # --- Regularization Parameters ---\n",
    "    max_depth=4,                # Reduced from 6. Forces simpler trees.\n",
    "    min_child_weight=5,         # Requires more data to make a split (prevents isolating outliers)\n",
    "    gamma=0.2,                  # Minimum loss reduction required to make a split\n",
    "    reg_alpha=1.0,              # L1 Regularization (Lasso) - kills useless features\n",
    "    reg_lambda=1.5,             # L2 Regularization (Ridge) - reduces weights\n",
    "    subsample=0.7,              # Use less data per tree to add randomness\n",
    "    colsample_bytree=0.7,       # Use fewer columns per tree\n",
    "    \n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=100,  # Give it more patience since LR is lower\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Reguralized Model...\")\n",
    "xgb_model_v2.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "# 3. Check Final Score\n",
    "val_preds_xgb = xgb_model_v2.predict_proba(X_val)[:, 1] # Get probabilities, not just 0/1\n",
    "final_auc = roc_auc_score(y_val, val_preds_xgb)\n",
    "\n",
    "print(f\"\\nFinal XGBoost Validation AUC: {final_auc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d281bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_xgb.csv saved!\n"
     ]
    }
   ],
   "source": [
    "# 1. Predict on Kaggle Test Set\n",
    "# Note: XGBoost uses predict_proba to get the score between 0 and 1\n",
    "# We take [:, 1] because that is the probability of class \"1\" (Diabetes)\n",
    "test_probs_xgb = xgb_model_v2.predict_proba(X_kaggle_test)[:, 1]\n",
    "\n",
    "# 2. Create Submission DataFrame\n",
    "submission_xgb = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'diagnosed_diabetes': test_probs_xgb\n",
    "})\n",
    "\n",
    "# 3. Save\n",
    "submission_xgb.to_csv('submission_xgb.csv', index=False)\n",
    "print(\"submission_xgb.csv saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
