{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9607a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (700000, 26)\n",
      "Test shape: (300000, 25)\n",
      "\n",
      "--- Train Data Head ---\n",
      "   id  age  alcohol_consumption_per_week  physical_activity_minutes_per_week  \\\n",
      "0   0   31                             1                                  45   \n",
      "1   1   50                             2                                  73   \n",
      "2   2   32                             3                                 158   \n",
      "3   3   54                             3                                  77   \n",
      "4   4   54                             1                                  55   \n",
      "\n",
      "   diet_score  sleep_hours_per_day  screen_time_hours_per_day   bmi  \\\n",
      "0         7.7                  6.8                        6.1  33.4   \n",
      "1         5.7                  6.5                        5.8  23.8   \n",
      "2         8.5                  7.4                        9.1  24.1   \n",
      "3         4.6                  7.0                        9.2  26.6   \n",
      "4         5.7                  6.2                        5.1  28.8   \n",
      "\n",
      "   waist_to_hip_ratio  systolic_bp  ...  gender  ethnicity  education_level  \\\n",
      "0                0.93          112  ...  Female   Hispanic       Highschool   \n",
      "1                0.83          120  ...  Female      White       Highschool   \n",
      "2                0.83           95  ...    Male   Hispanic       Highschool   \n",
      "3                0.83          121  ...  Female      White       Highschool   \n",
      "4                0.90          108  ...    Male      White       Highschool   \n",
      "\n",
      "   income_level  smoking_status  employment_status family_history_diabetes  \\\n",
      "0  Lower-Middle         Current           Employed                       0   \n",
      "1  Upper-Middle           Never           Employed                       0   \n",
      "2  Lower-Middle           Never            Retired                       0   \n",
      "3  Lower-Middle         Current           Employed                       0   \n",
      "4  Upper-Middle           Never            Retired                       0   \n",
      "\n",
      "  hypertension_history cardiovascular_history diagnosed_diabetes  \n",
      "0                    0                      0                1.0  \n",
      "1                    0                      0                1.0  \n",
      "2                    0                      0                0.0  \n",
      "3                    1                      0                1.0  \n",
      "4                    1                      0                1.0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "--- Submission Format Example ---\n",
      "       id  diagnosed_diabetes\n",
      "0  700000                   0\n",
      "1  700001                   0\n",
      "2  700002                   0\n",
      "3  700003                   0\n",
      "4  700004                   0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Load the datasets\n",
    "# Assuming the files are in the same directory as your script/notebook\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# 2. Basic sanity check - Print the size of the datasets\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# 3. Look at the first few rows to understand the features\n",
    "print(\"\\n--- Train Data Head ---\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\n--- Submission Format Example ---\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123bac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Separate Target and ID\n",
    "target = 'diagnosed_diabetes'\n",
    "# Drop rows in train where target might be missing (just in case)\n",
    "train_df = train_df.dropna(subset=[target]) \n",
    "\n",
    "y = train_df[target].values # The labels for training\n",
    "train_ids = train_df['id']\n",
    "test_ids = test_df['id']\n",
    "\n",
    "# 2. Drop unnecessary columns\n",
    "# We drop 'id' because it's just an index, not a feature\n",
    "# We drop 'diagnosed_diabetes' from train_df to match test_df structure for processing\n",
    "train_features = train_df.drop(['id', 'diagnosed_diabetes'], axis=1)\n",
    "test_features = test_df.drop(['id'], axis=1)\n",
    "\n",
    "# 3. Combine temporarily for consistent preprocessing\n",
    "# This ensures that if 'test' has a category 'train' doesn't (or vice versa), the columns still match\n",
    "all_features = pd.concat([train_features, test_features], axis=0)\n",
    "\n",
    "# --- IDENTIFY COLUMNS ---\n",
    "\n",
    "# Numerical columns (Continuous values)\n",
    "numerical_cols = [\n",
    "    'age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week',\n",
    "    'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day',\n",
    "    'bmi', 'waist_to_hip_ratio', 'systolic_bp'\n",
    "]\n",
    "\n",
    "# Categorical columns (Text/Strings)\n",
    "categorical_cols = [\n",
    "    'gender', 'ethnicity', 'education_level', \n",
    "    'income_level', 'smoking_status', 'employment_status'\n",
    "]\n",
    "\n",
    "# Binary/Already Numeric columns (0/1) - We usually leave these alone\n",
    "# (family_history_diabetes, hypertension_history, cardiovascular_history)\n",
    "\n",
    "# --- PREPROCESSING ---\n",
    "\n",
    "# A. Handle Categorical Data (One-Hot Encoding)\n",
    "# drop_first=True helps reduce redundancy (e.g., if is_Male=0, we know is_Female=1)\n",
    "all_features = pd.get_dummies(all_features, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# B. Handle Numerical Data (Scaling)\n",
    "scaler = StandardScaler()\n",
    "all_features[numerical_cols] = scaler.fit_transform(all_features[numerical_cols])\n",
    "\n",
    "# C. Handle Missing Values (Simple Imputation)\n",
    "# Fill numeric NaNs with Mean, others with 0\n",
    "all_features[numerical_cols] = all_features[numerical_cols].fillna(all_features[numerical_cols].mean())\n",
    "all_features = all_features.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e65baa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Input Shape: (560000, 36)\n",
      "Target Shape: (560000,)\n",
      "Validation Shape: (140000, 36)\n"
     ]
    }
   ],
   "source": [
    "# --- SPLIT BACK TO TRAIN / TEST ---\n",
    "\n",
    "# Split back using the original length of the train dataframe\n",
    "X = all_features.iloc[:len(train_df)].values\n",
    "X_kaggle_test = all_features.iloc[len(train_df):].values\n",
    "\n",
    "# --- CREATE VALIDATION SET ---\n",
    "# Essential for Neural Nets to stop training before overfitting\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Final Input Shape: {X_train.shape}\")\n",
    "print(f\"Target Shape: {y_train.shape}\")\n",
    "print(f\"Validation Shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4e9820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for non-numeric columns...\n",
      "         0         1         2         3         4         5         6   \\\n",
      "0 -0.373175 -0.073644 -0.106648  0.368804 -1.657032  0.092278  0.635062   \n",
      "1  0.989543   0.87543 -0.379345 -0.380158  1.213476  1.468802  0.844062   \n",
      "2 -1.565553 -0.073644 -0.197547 -1.537644 -0.994607  1.173833  0.112563   \n",
      "3  0.819204 -1.022719 -0.233907  0.232629  0.551051  1.321318 -0.758268   \n",
      "4  0.734034 -0.073644 -0.342985   2.34334 -0.884203  0.928025  0.983395   \n",
      "\n",
      "         7         8   9   ...     26     27     28     29     30     31  \\\n",
      "0  1.865628  0.061517  62  ...  False  False   True  False  False  False   \n",
      "1  1.079128  0.061517  86  ...  False  False  False   True  False   True   \n",
      "2  0.554794  0.693086  64  ...  False  False  False   True  False  False   \n",
      "3 -0.231706 -1.291843  70  ...  False  False  False  False   True  False   \n",
      "4  1.341294  0.422414  69  ...  False  False  False   True  False  False   \n",
      "\n",
      "      32     33     34     35  \n",
      "0  False  False  False  False  \n",
      "1  False  False  False  False  \n",
      "2   True  False  False  False  \n",
      "3   True  False  False  False  \n",
      "4  False  False  False  False  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "SUCCESS: Data converted to float32.\n"
     ]
    }
   ],
   "source": [
    "# 1. Check what columns are causing the issue (Debugging)\n",
    "print(\"Checking for non-numeric columns...\")\n",
    "# Convert back to DataFrame just to see dtypes\n",
    "temp_df = pd.DataFrame(X_train)\n",
    "# Print columns that are of type 'object'\n",
    "print(temp_df.select_dtypes(include=['object']).head())\n",
    "\n",
    "# 2. THE FIX: Force conversion to float32\n",
    "# This will turn Booleans (True/False) into 1.0/0.0\n",
    "# And if there are strings like '1', it converts them. \n",
    "# If there are strings like 'Male', it will crash and tell us exactly which one is wrong.\n",
    "try:\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_val = X_val.astype(np.float32)\n",
    "    y_train = y_train.astype(np.float32)\n",
    "    y_val = y_val.astype(np.float32)\n",
    "    print(\"SUCCESS: Data converted to float32.\")\n",
    "except ValueError as e:\n",
    "    print(\"ERROR: You still have text in your data that cannot be converted!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32106de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting XGBoost Training ---\n",
      "[0]\tvalidation_0-auc:0.62971\tvalidation_1-auc:0.62635\n",
      "[100]\tvalidation_0-auc:0.70705\tvalidation_1-auc:0.70466\n",
      "[200]\tvalidation_0-auc:0.71558\tvalidation_1-auc:0.71193\n",
      "[300]\tvalidation_0-auc:0.72085\tvalidation_1-auc:0.71547\n",
      "[400]\tvalidation_0-auc:0.72512\tvalidation_1-auc:0.71805\n",
      "[500]\tvalidation_0-auc:0.72829\tvalidation_1-auc:0.71960\n",
      "[600]\tvalidation_0-auc:0.73118\tvalidation_1-auc:0.72086\n",
      "[700]\tvalidation_0-auc:0.73373\tvalidation_1-auc:0.72193\n",
      "[800]\tvalidation_0-auc:0.73608\tvalidation_1-auc:0.72283\n",
      "[900]\tvalidation_0-auc:0.73818\tvalidation_1-auc:0.72352\n",
      "[1000]\tvalidation_0-auc:0.74008\tvalidation_1-auc:0.72400\n",
      "[1100]\tvalidation_0-auc:0.74184\tvalidation_1-auc:0.72434\n",
      "[1200]\tvalidation_0-auc:0.74343\tvalidation_1-auc:0.72461\n",
      "[1300]\tvalidation_0-auc:0.74503\tvalidation_1-auc:0.72486\n",
      "[1400]\tvalidation_0-auc:0.74664\tvalidation_1-auc:0.72502\n",
      "[1500]\tvalidation_0-auc:0.74824\tvalidation_1-auc:0.72526\n",
      "[1600]\tvalidation_0-auc:0.74973\tvalidation_1-auc:0.72543\n",
      "[1700]\tvalidation_0-auc:0.75116\tvalidation_1-auc:0.72558\n",
      "[1800]\tvalidation_0-auc:0.75260\tvalidation_1-auc:0.72569\n",
      "[1900]\tvalidation_0-auc:0.75396\tvalidation_1-auc:0.72581\n",
      "[1999]\tvalidation_0-auc:0.75537\tvalidation_1-auc:0.72591\n",
      "\n",
      "Final XGBoost Validation AUC: 0.72592\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"--- Starting XGBoost Training ---\")\n",
    "\n",
    "# 1. Define the Model\n",
    "# We use standard \"starter\" hyperparameters that usually work well\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=2000,          # Maximum number of trees\n",
    "    learning_rate=0.02,         # Slow learning to avoid overfitting\n",
    "    max_depth=6,                # Depth of each tree\n",
    "    subsample=0.8,              # Use 80% of rows per tree\n",
    "    colsample_bytree=0.8,       # Use 80% of columns per tree\n",
    "    objective='binary:logistic',# For binary classification\n",
    "    eval_metric='auc',          # The metric we care about\n",
    "    random_state=42,\n",
    "    early_stopping_rounds=50,   # Stop if validation score doesn't improve for 50 rounds\n",
    "    n_jobs=-1                   # Use all CPU cores\n",
    ")\n",
    "\n",
    "# 2. Train the Model\n",
    "# We pass the validation set here so it can calculate AUC live\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=100  # Print progress every 100 rounds\n",
    ")\n",
    "\n",
    "# 3. Check Final Score\n",
    "val_preds_xgb = xgb_model.predict_proba(X_val)[:, 1] # Get probabilities, not just 0/1\n",
    "final_auc = roc_auc_score(y_val, val_preds_xgb)\n",
    "\n",
    "print(f\"\\nFinal XGBoost Validation AUC: {final_auc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d281bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_xgb.csv saved!\n"
     ]
    }
   ],
   "source": [
    "# 1. Predict on Kaggle Test Set\n",
    "# Note: XGBoost uses predict_proba to get the score between 0 and 1\n",
    "# We take [:, 1] because that is the probability of class \"1\" (Diabetes)\n",
    "test_probs_xgb = xgb_model.predict_proba(X_kaggle_test)[:, 1]\n",
    "\n",
    "# 2. Create Submission DataFrame\n",
    "submission_xgb = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'diagnosed_diabetes': test_probs_xgb\n",
    "})\n",
    "\n",
    "# 3. Save\n",
    "submission_xgb.to_csv('submission_xgb.csv', index=False)\n",
    "print(\"submission_xgb.csv saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
