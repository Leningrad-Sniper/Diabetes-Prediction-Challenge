{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9607a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (700000, 26)\n",
      "Test shape: (300000, 25)\n",
      "\n",
      "--- Train Data Head ---\n",
      "   id  age  alcohol_consumption_per_week  physical_activity_minutes_per_week  \\\n",
      "0   0   31                             1                                  45   \n",
      "1   1   50                             2                                  73   \n",
      "2   2   32                             3                                 158   \n",
      "3   3   54                             3                                  77   \n",
      "4   4   54                             1                                  55   \n",
      "\n",
      "   diet_score  sleep_hours_per_day  screen_time_hours_per_day   bmi  \\\n",
      "0         7.7                  6.8                        6.1  33.4   \n",
      "1         5.7                  6.5                        5.8  23.8   \n",
      "2         8.5                  7.4                        9.1  24.1   \n",
      "3         4.6                  7.0                        9.2  26.6   \n",
      "4         5.7                  6.2                        5.1  28.8   \n",
      "\n",
      "   waist_to_hip_ratio  systolic_bp  ...  gender  ethnicity  education_level  \\\n",
      "0                0.93          112  ...  Female   Hispanic       Highschool   \n",
      "1                0.83          120  ...  Female      White       Highschool   \n",
      "2                0.83           95  ...    Male   Hispanic       Highschool   \n",
      "3                0.83          121  ...  Female      White       Highschool   \n",
      "4                0.90          108  ...    Male      White       Highschool   \n",
      "\n",
      "   income_level  smoking_status  employment_status family_history_diabetes  \\\n",
      "0  Lower-Middle         Current           Employed                       0   \n",
      "1  Upper-Middle           Never           Employed                       0   \n",
      "2  Lower-Middle           Never            Retired                       0   \n",
      "3  Lower-Middle         Current           Employed                       0   \n",
      "4  Upper-Middle           Never            Retired                       0   \n",
      "\n",
      "  hypertension_history cardiovascular_history diagnosed_diabetes  \n",
      "0                    0                      0                1.0  \n",
      "1                    0                      0                1.0  \n",
      "2                    0                      0                0.0  \n",
      "3                    1                      0                1.0  \n",
      "4                    1                      0                1.0  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "--- Submission Format Example ---\n",
      "       id  diagnosed_diabetes\n",
      "0  700000                   0\n",
      "1  700001                   0\n",
      "2  700002                   0\n",
      "3  700003                   0\n",
      "4  700004                   0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Load the datasets\n",
    "# Assuming the files are in the same directory as your script/notebook\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# 2. Basic sanity check - Print the size of the datasets\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# 3. Look at the first few rows to understand the features\n",
    "print(\"\\n--- Train Data Head ---\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\n--- Submission Format Example ---\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123bac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Separate Target and ID\n",
    "target = 'diagnosed_diabetes'\n",
    "# Drop rows in train where target might be missing (just in case)\n",
    "train_df = train_df.dropna(subset=[target]) \n",
    "\n",
    "y = train_df[target].values # The labels for training\n",
    "train_ids = train_df['id']\n",
    "test_ids = test_df['id']\n",
    "\n",
    "# 2. Drop unnecessary columns\n",
    "# We drop 'id' because it's just an index, not a feature\n",
    "# We drop 'diagnosed_diabetes' from train_df to match test_df structure for processing\n",
    "train_features = train_df.drop(['id', 'diagnosed_diabetes'], axis=1)\n",
    "test_features = test_df.drop(['id'], axis=1)\n",
    "\n",
    "# 3. Combine temporarily for consistent preprocessing\n",
    "# This ensures that if 'test' has a category 'train' doesn't (or vice versa), the columns still match\n",
    "all_features = pd.concat([train_features, test_features], axis=0)\n",
    "\n",
    "# --- IDENTIFY COLUMNS ---\n",
    "\n",
    "# Numerical columns (Continuous values)\n",
    "numerical_cols = [\n",
    "    'age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week',\n",
    "    'diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day',\n",
    "    'bmi', 'waist_to_hip_ratio', 'systolic_bp'\n",
    "]\n",
    "\n",
    "# Categorical columns (Text/Strings)\n",
    "categorical_cols = [\n",
    "    'gender', 'ethnicity', 'education_level', \n",
    "    'income_level', 'smoking_status', 'employment_status'\n",
    "]\n",
    "\n",
    "# Binary/Already Numeric columns (0/1) - We usually leave these alone\n",
    "# (family_history_diabetes, hypertension_history, cardiovascular_history)\n",
    "\n",
    "# --- PREPROCESSING ---\n",
    "\n",
    "# A. Handle Categorical Data (One-Hot Encoding)\n",
    "# drop_first=True helps reduce redundancy (e.g., if is_Male=0, we know is_Female=1)\n",
    "all_features = pd.get_dummies(all_features, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# B. Handle Numerical Data (Scaling)\n",
    "scaler = StandardScaler()\n",
    "all_features[numerical_cols] = scaler.fit_transform(all_features[numerical_cols])\n",
    "\n",
    "# C. Handle Missing Values (Simple Imputation)\n",
    "# Fill numeric NaNs with Mean, others with 0\n",
    "all_features[numerical_cols] = all_features[numerical_cols].fillna(all_features[numerical_cols].mean())\n",
    "all_features = all_features.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e65baa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Input Shape: (560000, 36)\n",
      "Target Shape: (560000,)\n",
      "Validation Shape: (140000, 36)\n"
     ]
    }
   ],
   "source": [
    "# --- SPLIT BACK TO TRAIN / TEST ---\n",
    "\n",
    "# Split back using the original length of the train dataframe\n",
    "X = all_features.iloc[:len(train_df)].values\n",
    "X_kaggle_test = all_features.iloc[len(train_df):].values\n",
    "\n",
    "# --- CREATE VALIDATION SET ---\n",
    "# Essential for Neural Nets to stop training before overfitting\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Final Input Shape: {X_train.shape}\")\n",
    "print(f\"Target Shape: {y_train.shape}\")\n",
    "print(f\"Validation Shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d4e9820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for non-numeric columns...\n",
      "         0         1         2         3         4         5         6   \\\n",
      "0 -0.373175 -0.073644 -0.106648  0.368804 -1.657032  0.092278  0.635062   \n",
      "1  0.989543   0.87543 -0.379345 -0.380158  1.213476  1.468802  0.844062   \n",
      "2 -1.565553 -0.073644 -0.197547 -1.537644 -0.994607  1.173833  0.112563   \n",
      "3  0.819204 -1.022719 -0.233907  0.232629  0.551051  1.321318 -0.758268   \n",
      "4  0.734034 -0.073644 -0.342985   2.34334 -0.884203  0.928025  0.983395   \n",
      "\n",
      "         7         8   9   ...     26     27     28     29     30     31  \\\n",
      "0  1.865628  0.061517  62  ...  False  False   True  False  False  False   \n",
      "1  1.079128  0.061517  86  ...  False  False  False   True  False   True   \n",
      "2  0.554794  0.693086  64  ...  False  False  False   True  False  False   \n",
      "3 -0.231706 -1.291843  70  ...  False  False  False  False   True  False   \n",
      "4  1.341294  0.422414  69  ...  False  False  False   True  False  False   \n",
      "\n",
      "      32     33     34     35  \n",
      "0  False  False  False  False  \n",
      "1  False  False  False  False  \n",
      "2   True  False  False  False  \n",
      "3   True  False  False  False  \n",
      "4  False  False  False  False  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "SUCCESS: Data converted to float32.\n"
     ]
    }
   ],
   "source": [
    "# 1. Check what columns are causing the issue (Debugging)\n",
    "print(\"Checking for non-numeric columns...\")\n",
    "# Convert back to DataFrame just to see dtypes\n",
    "temp_df = pd.DataFrame(X_train)\n",
    "# Print columns that are of type 'object'\n",
    "print(temp_df.select_dtypes(include=['object']).head())\n",
    "\n",
    "# 2. THE FIX: Force conversion to float32\n",
    "# This will turn Booleans (True/False) into 1.0/0.0\n",
    "# And if there are strings like '1', it converts them. \n",
    "# If there are strings like 'Male', it will crash and tell us exactly which one is wrong.\n",
    "try:\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_val = X_val.astype(np.float32)\n",
    "    y_train = y_train.astype(np.float32)\n",
    "    y_val = y_val.astype(np.float32)\n",
    "    print(\"SUCCESS: Data converted to float32.\")\n",
    "except ValueError as e:\n",
    "    print(\"ERROR: You still have text in your data that cannot be converted!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32106de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cpu\n",
      "--- Starting Training ---\n",
      "Epoch 5/30 | Avg Loss: 0.6079 | Val AUC: 0.6946\n",
      "Epoch 10/30 | Avg Loss: 0.6067 | Val AUC: 0.6951\n",
      "Epoch 15/30 | Avg Loss: 0.6059 | Val AUC: 0.6949\n",
      "Epoch 20/30 | Avg Loss: 0.6058 | Val AUC: 0.6949\n",
      "Epoch 25/30 | Avg Loss: 0.6054 | Val AUC: 0.6952\n",
      "Epoch 30/30 | Avg Loss: 0.6052 | Val AUC: 0.6943\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 1. Convert Data to PyTorch Tensors\n",
    "# We use the cleaned X_train/X_val from your previous fix\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 2. Define the Neural Network Architecture\n",
    "class DiabetesNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DiabetesNN, self).__init__()\n",
    "        \n",
    "        # Layer 1: Input -> Hidden (64)\n",
    "        self.layer1 = nn.Linear(input_dim, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Layer 2: Hidden (64) -> Hidden (32)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Layer 3: Hidden (32) -> Output (1)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        \n",
    "        # Activations\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.relu(self.bn1(self.layer1(x))))\n",
    "        x = self.dropout2(self.relu(self.bn2(self.layer2(x))))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "# 3. Setup Device & Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "model = DiabetesNN(input_dim=X_train.shape[1]).to(device)\n",
    "criterion = nn.BCELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 4. Training Loop\n",
    "epochs = 30 # A safe starting point\n",
    "batch_size = 1024\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "print(\"--- Starting Training ---\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Batch Training\n",
    "    permutation = torch.randperm(X_train_tensor.size()[0])\n",
    "    for i in range(0, X_train_tensor.size()[0], batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = X_train_tensor[indices].to(device), y_train_tensor[indices].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Validation Check\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_preds = model(X_val_tensor.to(device)).cpu().numpy()\n",
    "            val_auc = roc_auc_score(y_val, val_preds)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Avg Loss: {epoch_loss/(len(X_train)//batch_size):.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d281bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data converted to float32.\n",
      "submission.csv saved! Ready for upload.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Prepare the Kaggle Test Data\n",
    "# Apply the exact same fix we used on X_train\n",
    "try:\n",
    "    X_kaggle_test = X_kaggle_test.astype(np.float32)\n",
    "    print(\"Test data converted to float32.\")\n",
    "except ValueError:\n",
    "    print(\"Error converting test data.\")\n",
    "\n",
    "# 2. Convert to Tensor\n",
    "X_test_tensor = torch.tensor(X_kaggle_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# 3. Predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get raw probabilities\n",
    "    test_predictions = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "# 4. Create Submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'diagnosed_diabetes': test_predictions.flatten()\n",
    "})\n",
    "\n",
    "# 5. Save\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"submission.csv saved! Ready for upload.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
